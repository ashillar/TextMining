{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf951c3",
   "metadata": {},
   "source": [
    "# Using NLP to detect depression in tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58081541",
   "metadata": {},
   "source": [
    "- Description of the used data:https://www.kaggle.com/datasets/infamouscoder/mental-health-social-media/discussion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cda237",
   "metadata": {},
   "source": [
    "### Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c703d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from click->nltk) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from importlib-metadata->click->nltk) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (from importlib-metadata->click->nltk) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\yukyu\\anaconda3\\lib\\site-packages (0.0.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\yukyu\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad52ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e82526",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8178e92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>depression_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's just over 2 years since I was diagnosed w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's Sunday, I need a break, so I'm planning t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Awake but tired. I need to sleep but my brain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @SewHQ: #Retro bears make perfect gifts and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s hard to say whether packing lists are mak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  depression_label\n",
       "0  It's just over 2 years since I was diagnosed w...                 1\n",
       "1  It's Sunday, I need a break, so I'm planning t...                 1\n",
       "2  Awake but tired. I need to sleep but my brain ...                 1\n",
       "3  RT @SewHQ: #Retro bears make perfect gifts and...                 1\n",
       "4  It’s hard to say whether packing lists are mak...                 1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(r\"C:\\Users\\YukYu\\Downloads\\TM_project\\Mental-Health-Twitter.csv\")   \n",
    "df = pd.DataFrame(data, columns=['post_text','label'])\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['tweet','depression_label']\n",
    "\n",
    "# Selects 100 random rows\n",
    "# df = df.sample(n=100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6e3fd",
   "metadata": {},
   "source": [
    "## Nerc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852f8d3",
   "metadata": {},
   "source": [
    "- Find the named entities for each sentence POS, Word and Tag (see the kaggleset from Lab4)\n",
    "- Add it to new column of dataframe\n",
    "- Then compare with provided test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "55471747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>depression_label</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's just over 2 years since I was diagnosed w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[PRON, AUX, ADV, ADP, NUM, NOUN, SCONJ, PRON, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  depression_label  \\\n",
       "0  It's just over 2 years since I was diagnosed w...                 1   \n",
       "\n",
       "                                                 pos  \n",
       "0  [PRON, AUX, ADV, ADP, NUM, NOUN, SCONJ, PRON, ...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def ner(df):\n",
    "    df['pos'] = df['tweet'].apply(lambda x: [token.pos_ for token in nlp(x) if not token.is_space])\n",
    "    return df\n",
    "ner_table = ner(df)\n",
    "ner_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bddd4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split every tweet into individual words\n",
    "words = df['tweet'].str.split()\n",
    "\n",
    "# create a new dataframe with two columns: one for the original sentences, and another for the split words\n",
    "new_df = pd.DataFrame({'sentence': [tweet_words for tweet_words in words]})\n",
    "\n",
    "# print the new dataframe\n",
    "new_df['pos'] = df['tweet'].apply(lambda x: [token.pos_ for token in nlp(x) if not token.is_space])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ef2ffaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[It's, just, over, 2, years, since, I, was, di...</td>\n",
       "      <td>[PRON, AUX, ADV, ADP, NUM, NOUN, SCONJ, PRON, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[It's, Sunday,, I, need, a, break,, so, I'm, p...</td>\n",
       "      <td>[PRON, AUX, PROPN, PUNCT, PRON, VERB, DET, NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Awake, but, tired., I, need, to, sleep, but, ...</td>\n",
       "      <td>[ADJ, CCONJ, ADJ, PUNCT, PRON, VERB, PART, VER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[RT, @SewHQ:, #Retro, bears, make, perfect, gi...</td>\n",
       "      <td>[PROPN, NOUN, PUNCT, SYM, NOUN, NOUN, VERB, AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[It’s, hard, to, say, whether, packing, lists,...</td>\n",
       "      <td>[PRON, VERB, ADJ, PART, VERB, SCONJ, NOUN, NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[A, day, without, sunshine, is, like, night.]</td>\n",
       "      <td>[DET, NOUN, ADP, NOUN, AUX, ADP, NOUN, PUNCT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[Boren's, Laws:, (1), When, in, charge,, ponde...</td>\n",
       "      <td>[PROPN, PART, NOUN, PUNCT, PUNCT, X, PUNCT, SC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[The, flow, chart, is, a, most, thoroughly, ov...</td>\n",
       "      <td>[DET, NOUN, NOUN, AUX, DET, ADV, ADV, VERB, NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[Ships, are, safe, in, harbor,, but, they, wer...</td>\n",
       "      <td>[NOUN, AUX, ADJ, ADP, NOUN, PUNCT, CCONJ, PRON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[Black, holes, are, where, God, is, dividing, ...</td>\n",
       "      <td>[ADJ, NOUN, AUX, SCONJ, PROPN, AUX, VERB, ADP,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      [It's, just, over, 2, years, since, I, was, di...   \n",
       "1      [It's, Sunday,, I, need, a, break,, so, I'm, p...   \n",
       "2      [Awake, but, tired., I, need, to, sleep, but, ...   \n",
       "3      [RT, @SewHQ:, #Retro, bears, make, perfect, gi...   \n",
       "4      [It’s, hard, to, say, whether, packing, lists,...   \n",
       "...                                                  ...   \n",
       "19995      [A, day, without, sunshine, is, like, night.]   \n",
       "19996  [Boren's, Laws:, (1), When, in, charge,, ponde...   \n",
       "19997  [The, flow, chart, is, a, most, thoroughly, ov...   \n",
       "19998  [Ships, are, safe, in, harbor,, but, they, wer...   \n",
       "19999  [Black, holes, are, where, God, is, dividing, ...   \n",
       "\n",
       "                                                     pos  \n",
       "0      [PRON, AUX, ADV, ADP, NUM, NOUN, SCONJ, PRON, ...  \n",
       "1      [PRON, AUX, PROPN, PUNCT, PRON, VERB, DET, NOU...  \n",
       "2      [ADJ, CCONJ, ADJ, PUNCT, PRON, VERB, PART, VER...  \n",
       "3      [PROPN, NOUN, PUNCT, SYM, NOUN, NOUN, VERB, AD...  \n",
       "4      [PRON, VERB, ADJ, PART, VERB, SCONJ, NOUN, NOU...  \n",
       "...                                                  ...  \n",
       "19995      [DET, NOUN, ADP, NOUN, AUX, ADP, NOUN, PUNCT]  \n",
       "19996  [PROPN, PART, NOUN, PUNCT, PUNCT, X, PUNCT, SC...  \n",
       "19997  [DET, NOUN, NOUN, AUX, DET, ADV, ADV, VERB, NO...  \n",
       "19998  [NOUN, AUX, ADJ, ADP, NOUN, PUNCT, CCONJ, PRON...  \n",
       "19999  [ADJ, NOUN, AUX, SCONJ, PROPN, AUX, VERB, ADP,...  \n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a2fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
